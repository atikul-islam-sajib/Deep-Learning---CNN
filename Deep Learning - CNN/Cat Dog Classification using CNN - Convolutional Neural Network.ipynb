{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Cat Dog Classification using CNN - Convolutional Neural Network.ipynb","provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyNx2md050FkLb5nqi7RvNhY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"YGNkM9bxqhJG","executionInfo":{"status":"ok","timestamp":1660077464112,"user_tz":-120,"elapsed":832,"user":{"displayName":"Tamim Jahan","userId":"03086004763429564832"}}},"outputs":[],"source":["####### Import all necessity functions for Machine Learning ########\n","import pandas as pd\n","import numpy as np\n","import random\n","import seaborn as sns \n","import matplotlib.pyplot as plt\n","import scipy as shc\n","from sklearn.model_selection import train_test_split, KFold, StratifiedGroupKFold, GridSearchCV, RandomizedSearchCV\n","from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","from sklearn.feature_selection import VarianceThreshold, SelectKBest, chi2, mutual_info_classif, mutual_info_regression\n","from sklearn.decomposition import PCA\n","from imblearn.under_sampling import RandomUnderSampler, NearMiss\n","from imblearn.over_sampling import RandomOverSampler, SMOTE, SVMSMOTE, KMeansSMOTE, BorderlineSMOTE, ADASYN\n","from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.linear_model import LinearRegression, LogisticRegression, SGDClassifier, SGDRegressor, Perceptron\n","from sklearn.svm import SVC, SVR\n","from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n","from sklearn.ensemble import BaggingClassifier, BaggingRegressor, RandomForestClassifier, RandomForestRegressor, VotingClassifier, VotingRegressor, AdaBoostClassifier, AdaBoostRegressor\n","from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor, StackingClassifier, StackingRegressor\n","from xgboost import XGBClassifier, XGBRegressor\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, recall_score, f1_score, precision_score, r2_score, mean_absolute_error, mean_squared_error, silhouette_score"]},{"cell_type":"code","source":["####### Import the !pip install tensorflow-gpu ########\n","!pip install tensorflow-gpu"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jJ_cAU9Dw3D4","executionInfo":{"status":"ok","timestamp":1660077468450,"user_tz":-120,"elapsed":4340,"user":{"displayName":"Tamim Jahan","userId":"03086004763429564832"}},"outputId":"e80ecaf1-c046-4eaa-bf24-356881f0fc42"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tensorflow-gpu in /usr/local/lib/python3.7/dist-packages (2.9.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (57.4.0)\n","Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.12)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.21.6)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.15.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.14.1)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.2.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.2.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.2)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.3.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.26.0)\n","Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.9.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (21.3)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (4.1.1)\n","Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.9.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.6.3)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.0)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.17.3)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.1.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.47.0)\n","Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.9.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (14.0.6)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.4.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow-gpu) (0.37.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow-gpu) (1.5.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (3.4.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (1.8.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (1.35.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (2.23.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (0.6.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (0.4.6)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu) (4.2.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu) (4.9)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow-gpu) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow-gpu) (4.12.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow-gpu) (3.8.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu) (0.4.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu) (2.10)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow-gpu) (3.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow-gpu) (3.0.9)\n"]}]},{"cell_type":"code","source":["####### Import all necessity function for Deep Learning ########\n","import os\n","import cv2\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, LeakyReLU, PReLU, ELU, BatchNormalization, Dropout, Conv2D, MaxPool2D, MaxPool3D, Flatten\n","from tensorflow.keras.initializers import HeNormal, HeUniform, GlorotNormal, GlorotUniform\n","from tensorflow.keras.activations import relu, sigmoid, softmax, swish\n","from tensorflow.keras.regularizers import L1, L2, L1L2\n","from tensorflow.keras.losses import BinaryCrossentropy, CategoricalCrossentropy, SparseCategoricalCrossentropy, MSE, MAE, Huber\n","from tensorflow.keras.optimizers import SGD, Adagrad, Adadelta, RMSprop, Adam, Adamax, Nadam\n","\n","\n"],"metadata":{"id":"kPgJnoWEt3P0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["######## In order to access from google colab to Google Drive #########\n","from google.colab import drive\n","drive.mount('/content/drive',force_remount=True)"],"metadata":{"id":"dBJPS8q9t3TL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["######## In order to Unzip the folder in Google Drive #########\n","import zipfile\n","zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/CNN Dataset/StrawberryLeaf.zip\", 'r')\n","zip_ref.extractall()\n","zip_ref.close()\n","print(\"Unzip has been done successfully.\")"],"metadata":{"id":"m7b918p7ymjH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["####### DIRECTORY variable should be created to extract the data from the folder ########\n","_DIRECTORY  = '/content/StrawberryLeaf'\n","####### In that cat_dog folder the target categories are cat and dog #######\n","categories_ = ['Strawberry___Leaf_scorch', 'Strawberry___healthy']\n","####### Create a list named data #######\n","data_ = []\n","####### Extract the cat and dog from the folder ########\n","for i in categories_:\n","  folderPath_ = os.path.join(_DIRECTORY, i)\n","  for image_ in os.listdir(folderPath_):\n","    targetLabel_ = categories_.index(i)\n","    filePath_    = os.path.join(folderPath_, image_)\n","    ######## Now we will have to convert the image to array using cv2 #########\n","    imageArray_  = cv2.imread(filePath_)\n","    ######## Each image containg cat and dog might be different - so we should be converted into the exact same size ########\n","    imageArray_ = cv2.resize(imageArray_, (100, 100))\n","    ######## append the image Array into data ########\n","    data_.append([imageArray_, targetLabel_])\n","  \n","  print(f\"{i} folder is completed.\")"],"metadata":{"id":"pBksMohGymlh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["####### Shuffle the dataset #######\n","random.shuffle(data_)"],"metadata":{"id":"ajHVlTcaymnz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["####### Organized the dataset into X and y ########\n","X = []\n","y = []\n","for value_ in data_:\n","  ###### append the vector of the image into X ######\n","  X.append(value_[0])\n","  ###### append the vector of the image into y ######\n","  y.append(value_[1])\n","\n","print(\"Appending is completed\")"],"metadata":{"id":"r-_WryGG7KUZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["###### Convert the X into numpy #######\n","X = np.array(X)\n","y = np.array(y)\n","###### Divided this X with 255 to normalized ######\n","X = X/255"],"metadata":{"id":"sZsoW7AIymqQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["###### print the shape of X ######\n","print(\"Total # of records in this dataset is = \", X.shape[0],'\\n')\n","print(\"The shape of this dataset is = \", X.shape[1:],'\\n')"],"metadata":{"id":"I_Iwe7sKymsR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["####### Train and test split the dataset ########\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 42)\n","####### print the shape of this dataset #######\n","print(\"X_train shape is = \", X_train.shape,'\\n')\n","print(\"X_test  shape is = \", X_test.shape,'\\n')\n","print(\"y_train shape is = \", y_train.shape,'\\n')\n","print(\"y_test  shape is = \", y_test.shape,'\\n')"],"metadata":{"id":"MdsBuPdLymvv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = Sequential()\n","\n","model.add(Conv2D(64, (3,3), activation = 'relu', input_shape = (X.shape[1:])))\n","model.add(MaxPool2D(2,2))\n","\n","# model.add(Conv2D(64, (3,3), activation = 'relu'))\n","# model.add(MaxPool2D(2,2))\n","\n","\n","model.add(Flatten())\n","\n","model.add(Dense(128, activation = 'relu'))\n","model.add(Dense(32, activation = 'relu'))\n","model.add(Dense(1, activation = 'sigmoid'))"],"metadata":{"id":"8hMPlVhOrn80"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"],"metadata":{"id":"Y31niONeKrqt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.fit(X, y, validation_split=0.30, epochs = 10, batch_size = 24)"],"metadata":{"id":"6GA8klrkKwGZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predicted_ = np.where(model.predict(X_test) > 0.5, 1, 0)\n","print(\"accuracy score  = \", accuracy_score(predicted_, y_test))\n","print(\"recall score    = \", recall_score(predicted_, y_test))\n","print(\"precision score = \", precision_score(predicted_, y_test))\n","print(\"f1_score score  = \", f1_score(predicted_, y_test))"],"metadata":{"id":"xLKgL0AIR5PW"},"execution_count":null,"outputs":[]}]}